# =============================================================================
# M√ìDULO DE AN√ÅLISE DE SENSIBILIDADE
# =============================================================================
# Este m√≥dulo implementa t√©cnicas de an√°lise de sensibilidade para o modelo
# de otimiza√ß√£o, essenciais para entender a robustez da solu√ß√£o.
#
# AN√ÅLISES IMPLEMENTADAS:
# 1. Shadow Prices (Pre√ßos-Sombra): Valor marginal de relaxar cada restri√ß√£o
# 2. An√°lise de Intervalo: Como a solu√ß√£o muda com varia√ß√£o de par√¢metros
# 3. Gr√°fico de Tornado: Identifica par√¢metros mais influentes
# 4. An√°lise What-If: Cen√°rios alternativos de or√ßamento
#
# REFER√äNCIAS:
# - Winston, W. L. "Operations Research" - Cap. 6: Sensitivity Analysis
# - Hillier & Lieberman "Introduction to OR" - Cap. 7: Duality Theory
# =============================================================================

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from otimizacao import otimizar_alocacao, ResultadoOtimizacao


@dataclass
class ResultadoSensibilidade:
    """Armazena resultados da an√°lise de sensibilidade."""
    parametro: str
    valor_base: float
    valor_variado: float
    variacao_pct: float
    fo_base: float
    fo_variada: float
    impacto_fo_pct: float
    alocacao_mudou: bool


def analisar_sensibilidade_orcamento(
    df_dados: pd.DataFrame,
    orcamento_base: float,
    variacoes_pct: List[float] = [-20, -10, -5, 5, 10, 20, 50, 100]
) -> pd.DataFrame:
    """
    Analisa como a solu√ß√£o √≥tima muda com varia√ß√µes no or√ßamento dispon√≠vel.
    
    Esta √© a an√°lise de sensibilidade mais importante: quanto mais or√ßamento
    disponibilizamos, mais vidas salvamos - mas a que taxa?
    
    Args:
        df_dados: DataFrame com dados consolidados
        orcamento_base: Or√ßamento base para compara√ß√£o (R$ milh√µes)
        variacoes_pct: Lista de varia√ß√µes percentuais a testar
    
    Returns:
        DataFrame com resultados para cada cen√°rio de or√ßamento
    """
    resultados = []
    
    # Calcula solu√ß√£o base
    resultado_base = otimizar_alocacao(df_dados, orcamento_base)
    
    # Testa cada varia√ß√£o
    for var_pct in variacoes_pct:
        orcamento_var = orcamento_base * (1 + var_pct / 100)
        
        resultado = otimizar_alocacao(df_dados, orcamento_var)
        
        if resultado.status == 'Optimal':
            # Calcula m√©tricas comparativas
            delta_reducao = resultado.reducao_crimes - resultado_base.reducao_crimes
            eficiencia_marginal = (
                delta_reducao / (orcamento_var - orcamento_base) 
                if var_pct != 0 else 0
            )
            
            resultados.append({
                'variacao_pct': var_pct,
                'orcamento_milhoes': orcamento_var,
                'orcamento_usado': resultado.orcamento_usado,
                'reducao_crimes': resultado.reducao_crimes,
                'reducao_pct': resultado.reducao_percentual,
                'delta_reducao': delta_reducao,
                'eficiencia_marginal': round(eficiencia_marginal, 4),
                'custo_por_vida': round(
                    resultado.orcamento_usado / resultado.reducao_crimes 
                    if resultado.reducao_crimes > 0 else 0, 2
                ),
                'status': resultado.status
            })
    
    return pd.DataFrame(resultados)


def analisar_sensibilidade_elasticidade(
    df_dados: pd.DataFrame,
    orcamento: float,
    estado_alvo: str,
    variacoes_pct: List[float] = [-50, -25, -10, 10, 25, 50]
) -> pd.DataFrame:
    """
    Analisa impacto de varia√ß√µes na elasticidade de um estado espec√≠fico.
    
    √ötil para entender: "E se a efici√™ncia do investimento neste estado
    for maior/menor do que estimamos?"
    
    Args:
        df_dados: DataFrame com dados consolidados
        orcamento: Or√ßamento dispon√≠vel (R$ milh√µes)
        estado_alvo: Sigla do estado para variar elasticidade
        variacoes_pct: Varia√ß√µes percentuais na elasticidade
    
    Returns:
        DataFrame com resultados para cada cen√°rio
    """
    resultados = []
    
    # Elasticidade original
    elast_original = df_dados.loc[
        df_dados['sigla'] == estado_alvo, 'elasticidade'
    ].values[0]
    
    # Resultado base
    resultado_base = otimizar_alocacao(df_dados, orcamento)
    invest_base = resultado_base.alocacao.loc[
        resultado_base.alocacao['sigla'] == estado_alvo, 'investimento_milhoes'
    ].values[0]
    
    for var_pct in variacoes_pct:
        # Cria c√≥pia e varia elasticidade
        df_var = df_dados.copy()
        nova_elast = elast_original * (1 + var_pct / 100)
        df_var.loc[df_var['sigla'] == estado_alvo, 'elasticidade'] = nova_elast
        
        resultado = otimizar_alocacao(df_var, orcamento)
        
        if resultado.status == 'Optimal':
            invest_novo = resultado.alocacao.loc[
                resultado.alocacao['sigla'] == estado_alvo, 'investimento_milhoes'
            ].values[0]
            
            resultados.append({
                'estado': estado_alvo,
                'variacao_elasticidade_pct': var_pct,
                'elasticidade_original': elast_original,
                'elasticidade_nova': nova_elast,
                'investimento_base': invest_base,
                'investimento_novo': invest_novo,
                'delta_investimento': invest_novo - invest_base,
                'reducao_crimes_total': resultado.reducao_crimes,
                'delta_reducao': resultado.reducao_crimes - resultado_base.reducao_crimes
            })
    
    return pd.DataFrame(resultados)


def calcular_shadow_prices(
    df_dados: pd.DataFrame,
    orcamento: float,
    delta: float = 100.0
) -> Dict[str, float]:
    """
    Calcula os pre√ßos-sombra (shadow prices) das restri√ß√µes.
    
    O pre√ßo-sombra indica quanto a fun√ß√£o objetivo melhoraria se
    relax√°ssemos a restri√ß√£o em uma unidade.
    
    Para a restri√ß√£o de or√ßamento:
    Shadow Price = ŒîVidas_Salvas / ŒîOr√ßamento
    
    Interpreta√ß√£o: "Cada R$ 1 milh√£o adicional salva X vidas"
    
    Args:
        df_dados: DataFrame com dados consolidados
        orcamento: Or√ßamento base
        delta: Varia√ß√£o para calcular derivada num√©rica (R$ milh√µes)
               Usar delta maior (100) para capturar varia√ß√£o marginal corretamente
    
    Returns:
        Dicion√°rio com pre√ßos-sombra por restri√ß√£o
    """
    # Resultado base
    resultado_base = otimizar_alocacao(df_dados, orcamento)
    
    # Varia√ß√£o no or√ßamento total (usa delta maior para capturar varia√ß√£o)
    resultado_mais = otimizar_alocacao(df_dados, orcamento + delta)
    resultado_menos = otimizar_alocacao(df_dados, orcamento - delta)
    
    # Shadow price do or√ßamento (derivada central)
    shadow_orcamento = (
        resultado_mais.reducao_crimes - resultado_menos.reducao_crimes
    ) / (2 * delta)
    
    shadow_prices = {
        'orcamento_total': round(shadow_orcamento, 4),
        'interpretacao': f"Cada R$ 1 milh√£o adicional salva ~{shadow_orcamento:.2f} vidas"
    }
    
    # Shadow prices dos limites por estado
    for _, row in df_dados.iterrows():
        if pd.isna(row['orcamento_2022_milhoes']):
            continue
            
        estado = row['sigla']
        
        # Verifica se a restri√ß√£o de m√°ximo est√° ativa
        aloc = resultado_base.alocacao
        invest = aloc.loc[aloc['sigla'] == estado, 'investimento_milhoes'].values
        
        if len(invest) > 0:
            limite_max = row['orcamento_2022_milhoes'] * 0.30  # 30% default
            
            # Se investimento est√° no limite, a restri√ß√£o est√° ativa
            if abs(invest[0] - limite_max) < 0.01:
                shadow_prices[f'limite_max_{estado}'] = "ATIVO"
    
    return shadow_prices


def gerar_grafico_tornado(
    df_dados: pd.DataFrame,
    orcamento: float,
    top_n: int = 10
) -> go.Figure:
    """
    Gera gr√°fico de tornado mostrando sensibilidade aos par√¢metros.
    
    O gr√°fico de tornado √© uma ferramenta visual que mostra quais
    par√¢metros t√™m maior impacto na solu√ß√£o quando variados.
    
    Args:
        df_dados: DataFrame com dados consolidados
        orcamento: Or√ßamento base
        top_n: N√∫mero de par√¢metros a mostrar
    
    Returns:
        Figura Plotly com gr√°fico de tornado
    """
    # Resultado base
    resultado_base = otimizar_alocacao(df_dados, orcamento)
    base_reducao = resultado_base.reducao_crimes
    
    impactos = []
    
    # Testa varia√ß√£o de elasticidade para cada estado
    for _, row in df_dados.iterrows():
        if pd.isna(row['elasticidade']):
            continue
        
        estado = row['sigla']
        elast_original = row['elasticidade']
        
        # Varia elasticidade em +/- 20%
        for var in [-0.20, 0.20]:
            df_var = df_dados.copy()
            df_var.loc[df_var['sigla'] == estado, 'elasticidade'] = elast_original * (1 + var)
            
            resultado = otimizar_alocacao(df_var, orcamento)
            
            if resultado.status == 'Optimal':
                impacto = resultado.reducao_crimes - base_reducao
                impactos.append({
                    'parametro': f"Elasticidade {estado}",
                    'variacao': '+20%' if var > 0 else '-20%',
                    'impacto': impacto,
                    'impacto_abs': abs(impacto)
                })
    
    # Ordena por impacto absoluto
    df_impactos = pd.DataFrame(impactos)
    
    if len(df_impactos) == 0:
        return go.Figure()
    
    # Agrupa por par√¢metro e pega m√°ximo impacto
    df_agg = df_impactos.groupby('parametro')['impacto_abs'].max().reset_index()
    df_agg = df_agg.nlargest(top_n, 'impacto_abs')
    
    # Pega valores positivos e negativos
    parametros_top = df_agg['parametro'].tolist()
    
    positivos = []
    negativos = []
    
    for param in parametros_top:
        df_param = df_impactos[df_impactos['parametro'] == param]
        pos = df_param[df_param['variacao'] == '+20%']['impacto'].values
        neg = df_param[df_param['variacao'] == '-20%']['impacto'].values
        
        positivos.append(pos[0] if len(pos) > 0 else 0)
        negativos.append(neg[0] if len(neg) > 0 else 0)
    
    # Cria gr√°fico de tornado
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        y=parametros_top,
        x=negativos,
        name='Redu√ß√£o -20%',
        orientation='h',
        marker_color='#ff6b6b'
    ))
    
    fig.add_trace(go.Bar(
        y=parametros_top,
        x=positivos,
        name='Aumento +20%',
        orientation='h',
        marker_color='#51cf66'
    ))
    
    fig.update_layout(
        title='Gr√°fico de Tornado: Sensibilidade da Elasticidade',
        xaxis_title='Impacto na Redu√ß√£o de Crimes (vidas)',
        yaxis_title='',
        barmode='relative',
        height=400 + top_n * 20,
        showlegend=True
    )
    
    return fig


def gerar_grafico_sensibilidade_orcamento(
    df_sensibilidade: pd.DataFrame
) -> go.Figure:
    """
    Gera gr√°fico de sensibilidade ao or√ßamento.
    
    Mostra como a redu√ß√£o de crimes varia com o or√ßamento dispon√≠vel,
    e a efici√™ncia marginal (vidas salvas por R$ adicional).
    
    Args:
        df_sensibilidade: DataFrame da fun√ß√£o analisar_sensibilidade_orcamento
    
    Returns:
        Figura Plotly com gr√°ficos combinados
    """
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=(
            'Redu√ß√£o de Crimes vs Or√ßamento',
            'Custo por Vida Salva vs Or√ßamento'
        ),
        vertical_spacing=0.15
    )
    
    # Gr√°fico 1: Redu√ß√£o de crimes
    fig.add_trace(
        go.Scatter(
            x=df_sensibilidade['orcamento_milhoes'],
            y=df_sensibilidade['reducao_crimes'],
            mode='lines+markers',
            name='Vidas Salvas',
            line=dict(color='#2ecc71', width=3),
            marker=dict(size=10)
        ),
        row=1, col=1
    )
    
    # Gr√°fico 2: Custo por vida
    fig.add_trace(
        go.Scatter(
            x=df_sensibilidade['orcamento_milhoes'],
            y=df_sensibilidade['custo_por_vida'],
            mode='lines+markers',
            name='Custo/Vida (R$ mi)',
            line=dict(color='#e74c3c', width=3),
            marker=dict(size=10)
        ),
        row=2, col=1
    )
    
    fig.update_xaxes(title_text="Or√ßamento (R$ milh√µes)", row=1, col=1)
    fig.update_xaxes(title_text="Or√ßamento (R$ milh√µes)", row=2, col=1)
    fig.update_yaxes(title_text="Vidas Salvas", row=1, col=1)
    fig.update_yaxes(title_text="R$ milh√µes / vida", row=2, col=1)
    
    fig.update_layout(
        height=600,
        showlegend=False,
        title='An√°lise de Sensibilidade: Or√ßamento'
    )
    
    return fig


def analisar_cenarios(
    df_dados: pd.DataFrame,
    orcamentos: Dict[str, float]
) -> pd.DataFrame:
    """
    Executa an√°lise de cen√°rios com diferentes or√ßamentos.
    
    Args:
        df_dados: DataFrame com dados consolidados
        orcamentos: Dicion√°rio {nome_cenario: orcamento_milhoes}
    
    Returns:
        DataFrame comparativo entre cen√°rios
    """
    resultados = []
    
    for nome, orcamento in orcamentos.items():
        resultado = otimizar_alocacao(df_dados, orcamento)
        
        if resultado.status == 'Optimal':
            # Top 3 estados por investimento
            top3 = resultado.alocacao.nlargest(3, 'investimento_milhoes')['sigla'].tolist()
            
            resultados.append({
                'cenario': nome,
                'orcamento_milhoes': orcamento,
                'orcamento_bilhoes': orcamento / 1000,
                'reducao_crimes': resultado.reducao_crimes,
                'reducao_pct': resultado.reducao_percentual,
                'custo_por_vida': round(orcamento / resultado.reducao_crimes, 2),
                'top_3_estados': ', '.join(top3),
                'estados_atendidos': (resultado.alocacao['investimento_milhoes'] > 0).sum()
            })
    
    return pd.DataFrame(resultados)


# =============================================================================
# TESTE DO M√ìDULO
# =============================================================================
if __name__ == "__main__":
    from dados import carregar_dados_consolidados
    
    print("=" * 70)
    print("AN√ÅLISE DE SENSIBILIDADE")
    print("=" * 70)
    
    # Carrega dados
    df = carregar_dados_consolidados()
    orcamento_base = 5000  # R$ 5 bilh√µes
    
    print(f"\nüìä Or√ßamento base: R$ {orcamento_base:,} milh√µes")
    
    # 1. Sensibilidade ao or√ßamento
    print("\n" + "=" * 70)
    print("1. SENSIBILIDADE AO OR√áAMENTO")
    print("=" * 70)
    
    df_sens = analisar_sensibilidade_orcamento(df, orcamento_base)
    print(df_sens[['variacao_pct', 'orcamento_milhoes', 'reducao_crimes', 
                   'custo_por_vida']].to_string(index=False))
    
    # 2. Shadow Prices
    print("\n" + "=" * 70)
    print("2. PRE√áOS-SOMBRA (SHADOW PRICES)")
    print("=" * 70)
    
    shadow = calcular_shadow_prices(df, orcamento_base)
    for k, v in shadow.items():
        if not k.startswith('limite_max'):
            print(f"  {k}: {v}")
    
    restricoes_ativas = [k for k in shadow.keys() if k.startswith('limite_max')]
    print(f"\n  Restri√ß√µes de limite m√°ximo ativas: {len(restricoes_ativas)}")
    if restricoes_ativas:
        print(f"  Estados no limite: {[r.replace('limite_max_', '') for r in restricoes_ativas[:5]]}")
    
    # 3. An√°lise de cen√°rios
    print("\n" + "=" * 70)
    print("3. AN√ÅLISE DE CEN√ÅRIOS")
    print("=" * 70)
    
    cenarios = {
        'Conservador': 2000,
        'Moderado': 5000,
        'Ambicioso': 10000,
        'M√°ximo': 20000
    }
    
    df_cenarios = analisar_cenarios(df, cenarios)
    print(df_cenarios[['cenario', 'orcamento_bilhoes', 'reducao_crimes', 
                       'custo_por_vida', 'estados_atendidos']].to_string(index=False))
